# 抓取指导

下面的流程总结了重建「VIPRPG 紅白 2010」时踩过的坑，将其抽象成可复用的步骤。目标是把祭典站点的 HTML/资源抓取到 `catch/` 与 `public/`，并生成结构化的 `src/data/works/<slug>.json`。整个过程分为「线索搜集 → 本地缓存 → 资产校验 → 数据生成 → 复核归档」。

## 预备工作
- 建议使用 `npm`（含 `tsx`）、`curl`、`rg` 等工具，保证命令与脚本可直接运行。
- 在 `catch/` 目录下创建 `<slug>/` 的工作区：存放原始 HTML (`menu_top.html`、`menu_entry.html`、`entry/*.html|.png` 等) 与抓取摘要。
- 凡是从 Wayback Machine 获取的资源，都要记录其快照 URL，确保后续可复现。

## 站点链路确认
1. **首页/Banner**：从 Wayback Machine 或现存镜像打开祭典首页（示例：`https://web.archive.org/.../index.html` → `menu_top.html`）。
   - 只使用页面上真实存在的链接，禁止猜测路径。
   - Banner 下载后放入 `public/banners/<slug>.<ext>`，并在 summary 里记录来源快照。
2. **作品列表页**：按照首页导航找到作品列表（例：`index.html` → `index_entry.html` → `menu_entry.html`）。
   - 将 HTML 原样保存到 `catch/menu_entry.html`。
   - 列表中出现的所有链接、图标路径都要记录，后续按编号逐条抓取。
3. **作品详情页**：列表中的每个链接必须通过语义分析确认指向 `entry/<no>.html`。
   - 每获取一级页面，都要基于页面真实 href 构建下一级 URL。
   - 若直接站点访问失败，按 order：原站 → `web.archive.org/...fw_` → `...if_` → `...id_`。抓取脚本会自动尝试多种快照与 http/https 变体。

## 本地缓存策略
- HTML 快照统一命名为 `catch/entry/<no>_<label>.html`，`label` 使用来源 URL 的简写（脚本已有 `labelFromUrl` 逻辑可复用）。
- 原始截图/Icon 也可缓存于 `catch/entry/` 用于排查；最终入库的图标与截图分别写入 `public/icons/<slug>/`、`public/screenshots/<slug>/`。
- 若提前手动下载资源，请保留原始文件，脚本会检测已有文件避免重复请求。

## 脚本运行与核心逻辑
运行示例脚本：
```bash
npx tsx scripts/scrape-2010-kouhaku.ts
```
该脚本现已具备以下工程化保障：
- **多源重试**：对每个入口/截图依次尝试原站与 Wayback 多个时间戳，`fetchSnapshotTimestamps` 会补齐候选快照。
- **资源判定**：`bufferLooksLikeHtml` 会剔除 Wayback 的错误响应（HTML/脚本）与 0 字节文件，确保写入前都是有效二进制。
- **尺寸过滤**：`getImageDimensions` 横跨 PNG/JPG/GIF/BMP，拒绝宽高同时 <100px 的小图（常见于 32×32 图标）。
- **去重策略**：对通过尺寸校验的截图计算 MD5；若哈希重复则视为重复截图并跳过。
- **自动清理**：每次写入截图前调用 `purgeEntryScreenshots(no)`，清除旧版遗留文件，避免历史垃圾混入。
- **结果摘要**：`catch/<slug>-scrape-summary.json` 会记录缺失条目、跳过原因（`small`/`duplicate`）与所有尝试过的 URL，便于审计。

## 结果复核
1. **截图检查**：
   - 执行 `Get-ChildItem public/screenshots/<slug> | Where-Object { $_.Length -eq 0 }`，确认无 0 字节文件。
   - spot-check 几个条目确保截图确实来自详情页而不是图标。
2. **数据校验**：
   - `npm run validate:data` 确认 JSON 结构合规。
   - `npm run lint` 保障脚本与项目代码风格一致。
3. **比对摘要**：阅读 `catch/<slug>-scrape-summary.json`，关注 `note` 与 `skippedScreenshots` 字段，必要时回溯对应快照补抓。

## 常见问题与排查
- **快照缺失**：summary 中的 `failed:<url>` 表示所有候选都失败，可以尝试其他时间戳或寻找镜像站。务必把失败记录留在 summary 里。
- **混入图标**：若 summary 有大量 `small:` 项，说明详情页的结构特殊，需要手动剔除或调整阈值（默认 100px）。
- **重复截图**：`duplicate:` 表示同一作品只留下一张有效截图，此为预期行为。
- **站点结构差异**：如遇非表格布局，先更新脚本的解析逻辑（例如改写 `collectScreenshotCandidates`），再重新抓取并复核。

## 交付清单与版本管理
- `src/data/works/<slug>.json`：排序稳定、引用到 `/icons/...`、`/screenshots/...` 的相对路径，且已通过验证命令。
- `public/banners|icons|screenshots/<slug>/`：资源齐全且与 JSON 对应。
- `catch/<slug>-scrape-summary.json`：保留抓取时的上下文与异常说明。
- `catch/` 下的原始 HTML/快照：用于复查与将来脚本迭代。
- 更新 `catch/festival-scrape-status.md` 标记进度，必要时附上本次抓取的改动说明。

按照以上步骤，可以稳定复刻 2010 红白的流程，并快速迁移到其他祭典站点。
